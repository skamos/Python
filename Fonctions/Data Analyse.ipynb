{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf945c69-b44f-4000-8d8b-711b1d60e8f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3bed0d-7952-4d24-a72b-735a39721b7a",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### paramètres pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7be0b9-eee3-4b65-b483-dfbf0e8fdc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 184)\n",
    "pd.set_option('display.max_rows', 184)\n",
    "pd.set_option('display.min_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_seq_items', 184)\n",
    "pd.set_option('display.width', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abab081-0026-42a0-8cdf-c82ca235da91",
   "metadata": {
    "tags": []
   },
   "source": [
    "### utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3fbf6-d269-4f34-a437-c0e7d2b5980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chrono(object):  \n",
    "    def __init__(self):\n",
    "        self.start()\n",
    "    def start(self):  \n",
    "        if hasattr(self, 'interval'):  \n",
    "            del self.interval  \n",
    "        self.start_time = time.time()  \n",
    "  \n",
    "    def stop(self):  \n",
    "        if hasattr(self, 'start_time'):  \n",
    "            self.interval = time.time() - self.start_time  \n",
    "            del self.start_time # Force timer reinit  \n",
    "            print('{h}:%.3f temps passé'.format(h = int(self.interval//60)) % (self.interval%60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e6c46b-797c-46c3-9699-a56d089652e6",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2cc0e8-64f4-4234-902d-eca247ecb6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def netoyageCat(serie, seuil=20, new_val=\"Autre\", fillna=True):\n",
    "    '''\n",
    "    sur une série du df on retire les valeurs qui passe sous le seuil d'occurence pour les remplasser par la valeurs générique new_val\n",
    "    '''\n",
    "    mask_bool = serie.value_counts() < seuil\n",
    "    mask_autre = mask_bool.copy()\n",
    "    mask_autre[mask_bool] = new_val\n",
    "    serie = serie.replace(mask_autre[mask_bool])\n",
    "    if fillna:\n",
    "        serie.fillna(new_val, inplace=True)\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05678a58-99f5-42e6-ade8-98a41080eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiOnehotTags(serie, seuil=10, en='', clean=True):\n",
    "    '''\n",
    "    onehot pour une variable qui à plusieur valeurs dans une celule\n",
    "    '''\n",
    "    liste = listMainCat(serie=serie, seuil=seuil, en=en, clean=clean)\n",
    "    df_temp = pd.DataFrame(columns=liste.keys())\n",
    "    for i in serie.index:\n",
    "        val = serie.loc[i]\n",
    "        if type(val) == str:\n",
    "            for r in range(val.count(','+ en)+1):\n",
    "                virgule = val.find(',' + en)\n",
    "                if virgule == -1:\n",
    "                    if val[len(en):] in liste:\n",
    "                        df_temp.loc[i,val[len(en):]] = 1\n",
    "                    else:\n",
    "                        df_temp.loc[i] = 0\n",
    "                else:\n",
    "                    if val[len(en):virgule] in liste:\n",
    "                        df_temp.loc[i,val[len(en):virgule]] = 1\n",
    "                    else:\n",
    "                        df_temp.loc[i] = 0\n",
    "                    val = val[virgule + 1:]\n",
    "        else:\n",
    "            df_temp.loc[i] = 0\n",
    "    return df_temp.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d7e22-027a-43ae-a8f0-6110d8a775be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropOnehot(df, seuil):\n",
    "    '''\n",
    "    éjecte les colonnes qui sont remplie en dessous du seuil choisis\n",
    "    seuil peut être un entier et du coup il ejecte ceux qui sont moins que ce nombre\n",
    "    ou il peut être une fraction qui est le pourcentage en desous du quel il eject\n",
    "    éject aussi les one hot plein à 100%\n",
    "    '''\n",
    "    r=0\n",
    "    liste_drop = []\n",
    "    if isinstance(seuil, int):\n",
    "        for i in range(df.shape[1]):\n",
    "            if (df.iloc[:,i].value_counts()[1.0] < seuil) | (df.iloc[:,i].value_counts()[1.0]/df.shape[0] == 1):\n",
    "                liste_drop.append(df.columns[i])\n",
    "                r+=1\n",
    "    elif isinstance(seuil, float):\n",
    "        for i in range(df.shape[1]):\n",
    "            if (df.iloc[:,i].value_counts()[1.0]/df.shape[0] < seuil) | (df.iloc[:,i].value_counts()[1.0]/df.shape[0] == 1):\n",
    "                liste_drop.append(df.columns[i])\n",
    "                r+=1\n",
    "    print(r,' colonnes ejecte dans ', df.shape[1] ,' colonnes')\n",
    "    return df.drop(liste_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4598f374-998a-48ef-be1e-57d99eac969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fait un Onehot à la mano\n",
    "def Onehot(serie):\n",
    "    load=0\n",
    "    df_temp = pd.DataFrame()\n",
    "    for i in range(serie.shape[0]):\n",
    "        val = serie.iloc[i]\n",
    "        if type(val) == str:\n",
    "            df_temp.loc[i,val] = 1\n",
    "        else:\n",
    "            df_temp.loc[i,:] = 0\n",
    "        # bar de progression\n",
    "        if load < i//1000:\n",
    "            load = i//1000\n",
    "            clear_output(wait=True)\n",
    "            print(i, '/', serie.shape[0], '(%.4f)' % (i/serie.shape[0]))\n",
    "    df_temp.fillna(0, inplace=True)\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9075b865-ea83-47d9-b0fe-ccf8b299bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listMainCat(serie, seuil=10, en='', clean=True):\n",
    "    '''\n",
    "    liste dans la série toutes les valeurs existantes et trie du plus au moins frequent (ne considère pas ceux en dessous du seuil)\n",
    "    seuil peut être un entier et du coup il ejecte ceux qui sont moins que ce nombre\n",
    "    ou il peut être une fraction qui est le pourcentage en desous duquel il ejecte\n",
    "    clean permet de retirer les éspaces qui sont au début ou à la fin des chaines de caractères\n",
    "    '''\n",
    "    serie_temp = pd.Series()\n",
    "    serie_values = serie.value_counts()\n",
    "    for i in range(serie_values.shape[0]):\n",
    "        val = serie_values.index[i]\n",
    "        for r in range(val.count(',')+1):\n",
    "            if clean:\n",
    "                val = val.strip()\n",
    "            virgule = val.find(',')\n",
    "            if virgule == -1:\n",
    "                if val[len(en):] in serie_temp:\n",
    "                    serie_temp[val[len(en):]] += serie_values[i]\n",
    "                else:\n",
    "                    serie_temp[val[len(en):]] = serie_values[i]\n",
    "            else:\n",
    "                if val[len(en):virgule] in serie_temp:\n",
    "                    serie_temp[val[len(en):virgule]] += serie_values[i]\n",
    "                else:\n",
    "                    serie_temp[val[len(en):virgule]] = serie_values[i]\n",
    "                val = val[virgule+1:]\n",
    "    serie_temp.sort_values(ascending=False, inplace=True)\n",
    "    if isinstance(seuil, int):\n",
    "        for i in range(serie_temp.shape[0]):\n",
    "            if serie_temp.iloc[i] < seuil:\n",
    "                serie_temp = serie_temp.iloc[0:i]\n",
    "                break\n",
    "    elif isinstance(seuil, float):\n",
    "        for i in range(serie_temp.shape[0]):\n",
    "            if serie_temp.iloc[i]/serie.shape[0] < seuil:\n",
    "                serie_temp = serie_temp.iloc[0:i]\n",
    "                break\n",
    "    return serie_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8433d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_to_words( post_text, stopwords_lem=True):\n",
    "    # 1. Retire les caractères spéciaux et certains paternes non souhaités\n",
    "    post_text = re.sub(r\"(\\\\n)|(\\.\\\\n)|(\\'\\w+)|(http*\\S+)|[^\\w\\s\\.,#+-]\", \" \", post_text)\n",
    "    post_text = re.sub(r\"(\\.\\s)|(\\.$)|(,\\s)|(\\s#\\s)|(\\'\\w+)|(\\s\\-\\s)\", \" \", post_text)\n",
    "    post_text = re.sub(r\"(\\s-?\\+?\\d{0,4}\\s)\", \" \", post_text)\n",
    "    post_text = re.sub(r\"\\s+\", \" \", post_text)\n",
    "    # 2. passe tout en minuscule, et découpe les mots\n",
    "    words = post_text.lower().split()\n",
    "    if stopwords_lem :\n",
    "        # 3. Retire les Stop Words\n",
    "        words = [w for w in words if not w in stops]\n",
    "        # 4. Garde le radical des mots\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    return \" \".join( words )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc2309-4894-49d0-8c91-74177f1768bc",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a4793-7b61-483d-b7a7-74858d2d197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retourne le tableau de contingence\n",
    "def continTab(serieliste1, liste1, serieliste2, liste2, normalize=False):\n",
    "    reste = pd.Series()\n",
    "    df_cont = pd.DataFrame()\n",
    "    for i in range(liste1.shape[0]): # colonne\n",
    "        for r in range(liste2.shape[0]): # lignes\n",
    "            df_cont.loc[liste2.index[r], liste1.index[i]] = serieliste2[serieliste2.str.contains(liste2.index[r],na=False, regex=False) & serieliste1.str.contains(liste1.index[i],na=False, regex=False)].shape[0]\n",
    "        clear_output(wait=True)\n",
    "        print(i+1, '/', liste1.shape[0])\n",
    "        df_cont.loc['Le Reste',liste1.index[i]] = liste1[i] - df_cont[liste1.index[i]].sum()\n",
    "        if normalize:\n",
    "            df_cont = df_cont/df_cont[liste1.index[i]].sum()\n",
    "        df_cont.loc['Total',liste1.index[i]] = df_cont[liste1.index[i]].sum()\n",
    "        reste = serieliste1.str.contains(liste1.index[i],na=False, regex=False) | reste\n",
    "    for r in range(liste2.shape[0]):\n",
    "        df_cont.loc[liste2.index[r],'Le Reste'] = serieliste2[serieliste2.str.contains(liste2.index[r],na=False, regex=False) & ~reste].shape[0]\n",
    "    if normalize:\n",
    "        df_cont['Le Reste'] = df_cont['Le Reste']/df_cont['Le Reste'].sum()\n",
    "    df_cont['Total'] = df_cont.sum(axis=1)\n",
    "    if df_cont.loc['Le Reste'].sum() == 0:\n",
    "        df_cont.drop(['Le Reste'], axis=0, inplace=True)\n",
    "    if df_cont.loc[:,'Le Reste'].sum() == 0:\n",
    "        df_cont.drop(['Le Reste'], axis=1, inplace=True)\n",
    "    return df_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f967a-4f0c-49c1-9f1a-2fd9ae5cbe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correspTab(serielisteC, liste1, serielisteR, liste2, annot=False):\n",
    "    cont = continTab(serielisteC, liste1, serielisteR, liste2)\n",
    "    indep = cont.loc[:,[\"Total\"]].dot(cont.loc[[\"Total\"],:])/len(serielisteC)\n",
    "    measure = (cont-indep)**2/indep\n",
    "    xi_n = measure.sum().sum()\n",
    "    print(xi_n)\n",
    "    table = measure/xi_n\n",
    "    plt.figure(figsize=(.6*len(liste1),.6*len(liste2)))\n",
    "    if annot:\n",
    "        sns.heatmap(table.iloc[:-1,:-1], annot=cont.iloc[:-1,:-1], linewidths=.2)\n",
    "    else:\n",
    "        sns.heatmap(table.iloc[:-1,:-1], linewidths=.2)\n",
    "    plt.show()\n",
    "    return table, cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b39b284-b35b-478c-a8f1-52c172247ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listBarPlot(serie, serieliste, liste, n_plot=10, moy=False, Autre=False):\n",
    "    if liste.shape[0] < n_plot:\n",
    "        n_plot = liste.shape[0]\n",
    "    reste = pd.Series()\n",
    "    plt.figure(figsize=(30,7*((n_plot//4)+1)))\n",
    "    for i in range(n_plot):\n",
    "        plt.subplot((n_plot//4)+1, 4,i+1)\n",
    "        val_counts = serie[serieliste.str.contains(liste.index[i],na=False, regex=False)].value_counts()\n",
    "        if moy:\n",
    "            val_counts.plot.bar(title='{titre} (moyenne: {moy})'.format(titre = liste.index[i], moy = (val_counts.index * val_counts / val_counts.sum()).sum()))\n",
    "        else:\n",
    "            val_counts.plot.bar(title=liste.index[i])\n",
    "        reste = serieliste.str.contains(liste.index[i],na=False, regex=False) | reste\n",
    "        plt.legend()\n",
    "    if Autre:\n",
    "        plt.subplot((n_plot//4)+1, 4,i+2)\n",
    "        if moy:\n",
    "            serie[~reste].value_counts().plot.bar(title='Le Reste (moyenne: {moy})'.format(moy = (serie[~reste].value_counts().index * serie[~reste].value_counts() / serie[~reste].value_counts().sum()).sum()))\n",
    "        else:\n",
    "            serie[~reste].value_counts().plot.bar(title='Le Reste')\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89709511-5673-49f9-81e1-5d12326ee7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biListBarPlot(serieliste1, liste1, serieliste2, liste2, n_plot=10, n_cat=10,Autre=False):\n",
    "    if liste2.shape[0] < n_plot:\n",
    "        n_plot = liste2.shape[0]\n",
    "    reste = pd.Series()\n",
    "    plt.figure(figsize=(40,7*((n_plot//4)+1)))\n",
    "    for i in range(n_plot):\n",
    "        plt.subplot((n_plot//4)+1, 4, i+1)\n",
    "        serie_sum = pd.Series()\n",
    "        for r in range(n_cat):\n",
    "            serie_sum[liste1.index[r]] = serieliste1[serieliste1.str.contains(liste1.index[r],na=False, regex=False) & serieliste2.str.contains(liste2.index[i],na=False, regex=False)].shape[0]\n",
    "        serie_sum['Le Reste'] = liste2[i] - serie_sum.sum()\n",
    "        serie_sum.plot.bar(title=liste2.index[i])\n",
    "        reste = serieliste2.str.contains(liste2.index[i],na=False, regex=False) | reste\n",
    "        plt.legend()\n",
    "    if Autre:\n",
    "        plt.subplot((n_plot//4)+1, 4,i+2)\n",
    "        serie_sum = pd.Series()\n",
    "        for r in range(n_cat):\n",
    "            serie_sum[liste1.index[r]] = serieliste1[serieliste1.str.contains(liste1.index[r],na=False, regex=False) & reste].shape[0]\n",
    "        serie_sum.plot.bar(title='Le Reste')\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe3cbe-67f2-4b66-b17d-6335a2f3b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_hist(x, y, ax, ax_histx, ax_histy):\n",
    "    # no labels\n",
    "    ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "    ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "    # the scatter plot:\n",
    "    ax.scatter(x, y)\n",
    "\n",
    "    # now determine nice limits by hand:\n",
    "    binwidth = 0.25\n",
    "    xymax = max(np.max(np.abs(x)), np.max(np.abs(y)))\n",
    "    lim = (int(xymax/binwidth) + 1) * binwidth\n",
    "\n",
    "    bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "    ax_histx.hist(x, bins=bins)\n",
    "    ax_histy.hist(y, bins=bins, orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e72e10-c6fd-49eb-9a38-e765aaa8a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_identity(axes, *line_args, **line_kwargs):\n",
    "    identity, = axes.plot([], [], *line_args, **line_kwargs)\n",
    "    def callback(axes):\n",
    "        low_x, high_x = axes.get_xlim()\n",
    "        low_y, high_y = axes.get_ylim()\n",
    "        low = max(low_x, low_y)\n",
    "        high = min(high_x, high_y)\n",
    "        identity.set_data([low, high], [low, high])\n",
    "    callback(axes)\n",
    "    axes.callbacks.connect('xlim_changed', callback)\n",
    "    axes.callbacks.connect('ylim_changed', callback)\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a98c31-0501-4316-9c87-0fcb5c06f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf(model, std=False, exp=False):\n",
    "    '''\n",
    "    fait un graphique des performances du modèle par rapport aux vraies données\n",
    "    '''\n",
    "    plt.figure(figsize=(10,10))\n",
    "    ax = plt.subplot()\n",
    "    if std:\n",
    "        ax.scatter(model.predict(X_test_std), y_test)\n",
    "    elif exp:\n",
    "        ax.scatter(np.exp(model.predict(X_test)), y_test)\n",
    "    else:\n",
    "        ax.scatter(model.predict(X_test), y_test)\n",
    "    add_identity(ax, color='r', ls='--')\n",
    "    ax.set_aspect('equal')\n",
    "    plt.show\n",
    "    if std:\n",
    "        print('R2 : %3f'%(metrics.r2_score(y_test, model.predict(X_test_std))))\n",
    "    elif exp:\n",
    "        print('R2 : %3f'%(metrics.r2_score(y_test, np.exp(model.predict(X_test)))))\n",
    "    else:\n",
    "        print('R2 : %3f'%(metrics.r2_score(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88186922",
   "metadata": {},
   "source": [
    "#### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(model, feature_names, n_top_words, nb_line_plot, title):\n",
    "    '''\n",
    "    c'est pour les NMF\n",
    "    '''\n",
    "    rows = int(nb_line_plot)\n",
    "    fig, axes = plt.subplots(rows, 6, \n",
    "                             figsize=(30, rows*10), \n",
    "                             sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        if(topic_idx < nb_line_plot*6):\n",
    "            top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "            top_features = [feature_names[i] for i in top_features_ind]\n",
    "            weights = topic[top_features_ind]\n",
    "\n",
    "            ax = axes[topic_idx]\n",
    "            bartopic = ax.barh(top_features, weights, height=0.7)\n",
    "            bartopic[0].set_color('#f48023')\n",
    "            ax.set_title(f'Topic {topic_idx +1}',\n",
    "                         fontdict={'fontsize': 30})\n",
    "            ax.invert_yaxis()\n",
    "            ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "            for i in 'top right left'.split():\n",
    "                ax.spines[i].set_visible(False)\n",
    "            fig.suptitle(title, fontsize=36)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ab8ed-90d2-4374-b2c2-641bd226fca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelClass:\n",
    "    \"\"\"\n",
    "    Permet de manipuler différents modeles de Classification\n",
    "    (supervisé et non supervisé)\n",
    "    dans le même objet pour simplifier les comparaisons et visualisations\n",
    "    \"\"\"\n",
    "    def __init__(self, y_train: np.ndarray, y_test: np.ndarray, scoring: Optional[str] = None, prop_tags: Union[str, int] = 'origin'):\n",
    "        self.models = pd.DataFrame(columns=[\n",
    "            'name',\n",
    "            'data_use',\n",
    "            'model',\n",
    "            'confusion_matrice',\n",
    "            'Error',\n",
    "            'Jaccard Macro',\n",
    "            'Precision Macro',\n",
    "            'Recall Macro',\n",
    "            'F_mesure Macro',\n",
    "            'auc Macro',\n",
    "            'Jaccard Micro',\n",
    "            'Precision Micro',\n",
    "            'Recall Micro',\n",
    "            'F_mesure Micro',\n",
    "            'auc Micro',\n",
    "            'proportion_de_prédiction',\n",
    "            'fit_time',\n",
    "            'pred_time',\n",
    "            'y_pred',\n",
    "            'best_params',\n",
    "            'grid_params',\n",
    "            'grid_score',\n",
    "            'params'\n",
    "        ])\n",
    "        self.scoring = scoring\n",
    "        self.prop_tags = prop_tags\n",
    "        self.models.set_index('name', inplace=True)\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.x = {}\n",
    "    def save_data(self, path: str):\n",
    "        self.models.drop(['model'], axis=1).loc[self.models['y_pred'].notna()].to_pickle(path=path)\n",
    "        print('données du fichier '+ path + ' bien sauvegardé')\n",
    "    def append_data(self, path: str):\n",
    "        new_data = pd.read_pickle(path)\n",
    "        self.models = self.models.append(new_data)\n",
    "        print('données du fichier '+ path + ' bien chargé')\n",
    "    def add_model(self, name: str, model, params=None):\n",
    "        \"\"\"\n",
    "        Effectue une recherche par grille sur les paramètres.\n",
    "        \"\"\"\n",
    "        self.models.loc[name, 'data_use'] = 'no fit'\n",
    "        self.models.loc[name]['model'] = model\n",
    "        self.models.loc[name]['grid_params'] = params\n",
    "    def add_prediction(self, name: str, y_pred: np.ndarray, fit_time: float = 0, pred_time: float = 0):\n",
    "        \"\"\"\n",
    "        ajout des données prédites (utilisé pour les modeles non supervisés).\n",
    "        \"\"\"\n",
    "        self.models.loc[name, 'fit_time'] = fit_time\n",
    "        self.models.loc[name, 'pred_time'] = pred_time\n",
    "        self.models.loc[name]['y_pred'] = y_pred\n",
    "    def add_data(self, name: str, x_train, x_test):\n",
    "        self.x[name] = {\n",
    "            'x_train': x_train,\n",
    "            'x_test': x_test\n",
    "        }\n",
    "    def fit(self, name: Union[str, list] = 'all', data_name=None, cv: Optional[int] = None):\n",
    "        if name == 'all':\n",
    "            name = self.models.index.to_list()\n",
    "        elif type(name) == str:\n",
    "            print('préparation du modele ' + str(name))\n",
    "            self._fit_process(self.models.loc[name], data_name, cv)\n",
    "        elif type(name) == list:\n",
    "            print('préparation des modeles ' + ' '.join(name))\n",
    "            for model_name in name:\n",
    "                self._fit_process(self.models.loc[model_name], data_name, cv)\n",
    "    def _fit_process(self, model: pd.Series, data_name: str, cv: Optional[int]):\n",
    "        if data_name == None:\n",
    "            data_name = list(self.x.keys())[-1]\n",
    "        x_train = self.x[data_name]['x_train']\n",
    "        x_test = self.x[data_name]['x_test']\n",
    "        if model['grid_params'] != None:\n",
    "            grid = GridSearchCV(model['model'], model['grid_params'], cv=cv, scoring=self.scoring, verbose=3)\n",
    "            grid.fit(x_train, self.y_train)\n",
    "            model['grid_score'] = {\n",
    "                'mean_test_score': grid.cv_results_['mean_test_score'],\n",
    "                'mean_fit_time': grid.cv_results_['mean_fit_time'],\n",
    "                'mean_score_time': grid.cv_results_['mean_score_time'],\n",
    "                'params': grid.cv_results_['params']\n",
    "            }\n",
    "            model['model'] = grid.best_estimator_\n",
    "        start = time.time()\n",
    "        model['model'].fit(x_train, self.y_train)\n",
    "        stop = time.time()\n",
    "        print('le model ' + str(model.name) + ' à fini son entrainement')\n",
    "        model['fit_time'] = stop - start\n",
    "        model['best_params'] = model['model'].get_params()\n",
    "        model['data_use'] = data_name\n",
    "        start = time.time()\n",
    "        y_pred = np.array(model['model'].predict_proba(x_test))\n",
    "        stop = time.time()\n",
    "        model['pred_time'] = stop - start\n",
    "        if len(y_pred.shape) == 3:\n",
    "            model['y_pred'] = y_pred[:,:,1].T\n",
    "        elif len(y_pred.shape) == 2:\n",
    "            model['y_pred'] = y_pred\n",
    "        self.compute_perf(str(model.name))\n",
    "        print('tout est bon pour le modele ' + str(model.name))\n",
    "    def compute_perf(self, model_name: str, prop_tags: Optional[Union[str, int]] = None):\n",
    "        model: pd.Series = self.models.loc[model_name]\n",
    "        y_true: np.ndarray = self.y_test\n",
    "        y_pred: np.ndarray = model['y_pred']\n",
    "        n_classes = y_true.shape[1]\n",
    "        n_indiv = y_true.shape[0]\n",
    "        if not prop_tags :\n",
    "            prop_tags = self.prop_tags\n",
    "        if prop_tags == 'origin':\n",
    "            prop_tags = y_true.sum()/n_indiv\n",
    "        i = 0.5\n",
    "        seuil = 1\n",
    "        while i > 0.005 :\n",
    "            if (y_pred >= seuil).sum()/n_indiv < prop_tags :\n",
    "                seuil -= i\n",
    "            else :\n",
    "                seuil += i\n",
    "            i /= 2\n",
    "        y_predict = y_pred >= seuil\n",
    "        print('le seuil est: '+ str(seuil))\n",
    "        mcm = metrics.multilabel_confusion_matrix(y_true, y_predict)\n",
    "        tn = mcm[:, 0, 0].mean()\n",
    "        tp = mcm[:, 1, 1].mean()\n",
    "        fn = mcm[:, 1, 0].mean()\n",
    "        fp = mcm[:, 0, 1].mean()\n",
    "        model['confusion_matrice'] = [[tn, fn], [fp, tp]]\n",
    "        model['Error'] = metrics.hamming_loss(y_true, y_predict)\n",
    "        model['Jaccard Macro'] = metrics.jaccard_score(y_true, y_predict, average='macro')\n",
    "        model['Precision Macro'] = metrics.precision_score(y_true, y_predict, average='macro')\n",
    "        model['Recall Macro'] = metrics.recall_score(y_true, y_predict, average='macro')\n",
    "        model['F_mesure Macro'] = metrics.f1_score(y_true, y_predict, average='macro')\n",
    "        model['Jaccard Micro'] = metrics.jaccard_score(y_true, y_predict, average='micro')\n",
    "        model['Precision Micro'] = metrics.precision_score(y_true, y_predict, average='micro')\n",
    "        model['Recall Micro'] = metrics.recall_score(y_true, y_predict, average='micro')\n",
    "        model['F_mesure Micro'] = metrics.f1_score(y_true, y_predict, average='micro')\n",
    "        model['proportion_de_prédiction'] = (tp + fp)/(tp + fn)\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = metrics.roc_curve(y_true[:, i], y_pred[:, i])\n",
    "            if y_true[:, i].sum() == 0:\n",
    "                tpr[i] = fpr[i]\n",
    "            roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "        precision, recall, _ = metrics.precision_recall_curve(y_true.ravel(), y_pred.ravel())\n",
    "        \n",
    "        # Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "        roc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "        \n",
    "        # First aggregate all false positive rates\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        \n",
    "        # Then interpolate all ROC curves at this points\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "        # Finally average it and compute AUC\n",
    "        mean_tpr /= n_classes\n",
    "            \n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = metrics.auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "        \n",
    "        model['auc Micro'] = roc_auc[\"micro\"]\n",
    "        model['auc Macro'] = roc_auc[\"macro\"]\n",
    "        model['params'] = {\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr,\n",
    "            'roc_auc': roc_auc,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "    def plot_roc(self, model_list: list = [], plot_size: int = 10):\n",
    "        if model_list == []:\n",
    "            model_list = self.models.index.to_list()\n",
    "        lenth = len(model_list)\n",
    "        sqrt = math.floor(math.sqrt(lenth))\n",
    "        plt.figure(figsize=(plot_size*sqrt,plot_size*math.ceil(lenth/sqrt)))\n",
    "        for it, name in enumerate(model_list):\n",
    "            plt.subplot(math.ceil(lenth/sqrt), sqrt, it+1)\n",
    "            model = self.models.loc[name]\n",
    "            fpr = model['params']['fpr']\n",
    "            tpr = model['params']['tpr']\n",
    "            roc_auc = model['params']['roc_auc']\n",
    "            plt.plot(\n",
    "                fpr[\"micro\"],\n",
    "                tpr[\"micro\"],\n",
    "                label=\"micro-average Courbe ROC (surface = {0:0.2f})\".format(roc_auc[\"micro\"])\n",
    "            )\n",
    "            plt.plot(\n",
    "                fpr[\"macro\"],\n",
    "                tpr[\"macro\"],\n",
    "                label=\"macro-average Courbe ROC (surface = {0:0.2f})\".format(roc_auc[\"macro\"])\n",
    "            )\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xticks(fontsize=14)\n",
    "            plt.yticks(fontsize=14)\n",
    "            plt.xlabel(\"Ratio Faux Positif\", fontsize=14)\n",
    "            plt.ylabel(\"Ratio Vrais Positif\", fontsize=14)\n",
    "            plt.title(\"Courbe ROC du model : \"+ name, fontsize=16)\n",
    "            plt.legend(loc=\"lower right\", fontsize=12)\n",
    "        plt.show()\n",
    "    def plot_precision_recall(self, model_list: list = [], plot_size: int = 10):\n",
    "        if model_list == []:\n",
    "            model_list = self.models.index.to_list()\n",
    "        lenth = len(model_list)\n",
    "        sqrt = math.floor(math.sqrt(lenth))\n",
    "        plt.figure(figsize=(plot_size*sqrt,plot_size*math.ceil(lenth/sqrt)))\n",
    "        for it, name in enumerate(model_list):\n",
    "            plt.subplot(math.ceil(lenth/sqrt), sqrt, it+1)\n",
    "            model = self.models.loc[name]\n",
    "            precision = model['params']['precision']\n",
    "            recall = model['params']['recall']\n",
    "            plt.plot(\n",
    "                precision,\n",
    "                recall\n",
    "            )\n",
    "            plt.xticks(fontsize=14)\n",
    "            plt.yticks(fontsize=14)\n",
    "            plt.xlabel(\"Précision\", fontsize=14)\n",
    "            plt.ylabel(\"Recall\", fontsize=14)\n",
    "            plt.title(\"Courbe Précision Recall du model : \"+ name, fontsize=16)\n",
    "        plt.show()\n",
    "    def plot_perf(self, perf_list: List[str] = [], model_list: List = [], plot_size: int = 10):\n",
    "        if perf_list == []:\n",
    "            perf_list = ['Error', 'Jaccard Macro', 'Precision Macro',\n",
    "                        'Recall Macro', 'F_mesure Macro', 'auc Macro',\n",
    "                        'Jaccard Micro', 'Precision Micro', 'Recall Micro',\n",
    "                        'F_mesure Micro', 'auc Micro',\n",
    "                        'fit_time', 'pred_time']\n",
    "        if model_list == []:\n",
    "            models = self.models\n",
    "        else:\n",
    "            models = self.models.loc[model_list]\n",
    "        lenth = len(perf_list)\n",
    "        sqrt = math.floor(math.sqrt(lenth))\n",
    "        plt.figure(figsize=(plot_size*sqrt,plot_size*math.ceil(lenth/sqrt)))\n",
    "        for it, score in enumerate(perf_list):\n",
    "            plt.subplot(math.ceil(lenth/sqrt), sqrt, it+1)\n",
    "            value = models[score].values.astype('float')\n",
    "            colors = cm.winter(value / float(max(value)))\n",
    "            plt.bar(models.index, value, color = colors)\n",
    "            plt.title('Score '+score+' par Modele', fontsize=18)\n",
    "            plt.xticks(rotation=60, fontsize=14)\n",
    "            plt.yticks(fontsize=16)\n",
    "            plt.xlabel('')\n",
    "            plt.ylabel(score, fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    def plot_grid(self, model_name: str, plot_height: int = 10, model_lenth: float = 1.5):\n",
    "        model = self.models.loc[model_name]\n",
    "        params = []\n",
    "        val = ''\n",
    "        for param_list in model['grid_score']['params']:\n",
    "            for param in param_list.keys():\n",
    "                val+= str(param) + ': ' +str(param_list[param]) + '\\n'\n",
    "            params.append(val)\n",
    "            val = ''\n",
    "        plt.figure(figsize=(model_lenth*len(params), plot_height*3))\n",
    "        plt.suptitle('Grille de paramètre pour '+ model_name, fontsize=22)\n",
    "        plt.subplot(311)\n",
    "        value = model['grid_score']['mean_test_score']\n",
    "        colors = cm.winter(value / float(max(value)))\n",
    "        plt.bar(params, value, color = colors)\n",
    "        plt.title('Score moyen par paramètre', fontsize=18)\n",
    "        plt.xticks(rotation=30, fontsize=14)\n",
    "        plt.yticks(fontsize=16)\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('score moyen des folds', fontsize=14)\n",
    "        \n",
    "        plt.subplot(312)\n",
    "        value = model['grid_score']['mean_fit_time']\n",
    "        colors = cm.winter(value / float(max(value)))\n",
    "        plt.bar(params, value, color = colors)\n",
    "        plt.title('temp d\\'entrainement par paramètre', fontsize=18)\n",
    "        plt.xticks(rotation=30, fontsize=14)\n",
    "        plt.yticks(fontsize=16)\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('score moyen des folds', fontsize=14)\n",
    "        \n",
    "        plt.subplot(313)\n",
    "        value = model['grid_score']['mean_score_time']\n",
    "        colors = cm.winter(value / float(max(value)))\n",
    "        plt.bar(params, value, color = colors)\n",
    "        plt.title('temps de prédiction par paramètre', fontsize=18)\n",
    "        plt.xticks(rotation=30, fontsize=14)\n",
    "        plt.yticks(fontsize=16)\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('score moyen des folds', fontsize=14)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "        plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d14de00-9576-4de3-adcb-829268408436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import timeit\n",
    "from sklearn import metrics\n",
    "import math\n",
    "\n",
    "class ModelRegres:\n",
    "    def __init__(self):\n",
    "        self.result = pd.DataFrame(columns=[\n",
    "            'name',\n",
    "            'params',\n",
    "            'trainError',\n",
    "            'testError R2',\n",
    "            'testError RMSE',\n",
    "            'learningTime',\n",
    "            'predictTime'\n",
    "        ])\n",
    "        self.best_models = []\n",
    "    def err(self, model, X, y, scoring):\n",
    "        \"\"\"\n",
    "        Calcul de l'erreur du les prédictions du model\n",
    "        \"\"\"\n",
    "        if scoring == \"r2\":\n",
    "            return metrics.r2_score(y, model.predict(X))\n",
    "        elif scoring == 'neg_root_mean_squared_error':\n",
    "            return math.sqrt(np.mean((model.predict(X) - y) ** 2))\n",
    "        else:\n",
    "            print('scoring invalide')\n",
    "    def search(self, name, model, params, data, folds=5, verbose=1, scoring=\"r2\"):\n",
    "        \"\"\"\n",
    "        Effectue une recherche par grille sur les paramètres.\n",
    "        \"\"\"\n",
    "        if data:\n",
    "            X_train = data['X_train']\n",
    "            y_train = data['y_train']\n",
    "            X_test = data['X_test']\n",
    "            y_test = data['y_test']\n",
    "        \n",
    "        search = GridSearchCV(model, params, scoring=scoring, verbose=verbose, cv=folds, n_jobs=-1)\n",
    "        search.fit(X_train, y_train)\n",
    "        \n",
    "        self.result = self.result.append({\n",
    "            'name': name,\n",
    "            'params': search.best_params_,\n",
    "            'trainError': self.err(search.best_estimator_, X_train, y_train, scoring),\n",
    "            'testError R2': self.err(search.best_estimator_, X_test, y_test, 'r2'),\n",
    "            'testError RMSE': self.err(search.best_estimator_, X_test, y_test, 'neg_root_mean_squared_error'),\n",
    "            'learningTime': search.refit_time_,\n",
    "            'predictTime': 0\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "        self.best_models.append(search.best_estimator_)\n",
    "        print('Résultat ', name,' :')\n",
    "        print('Paramètres : ', search.best_params_)\n",
    "        print('Erreur sur le dataset d\\'entraînement : ', self.err(search.best_estimator_, X_train, y_train, scoring))\n",
    "        print('Erreur sur le dataset de test : ', self.err(search.best_estimator_, X_test, y_test, scoring))\n",
    "        print('Temps d\\'apprentissage : ', search.refit_time_)\n",
    "        \n",
    "        return search.cv_results_\n",
    "    def plot(self, name_model, grid, param1, name1, param2, name2):\n",
    "        try:\n",
    "            param2\n",
    "            name2\n",
    "            test = 1\n",
    "        except:\n",
    "            test = 2\n",
    "        if test == 1:\n",
    "            fig, ax = plt.subplots(1,1)\n",
    "            img = ax.imshow(np.log(-np.array(grid['mean_test_score']).reshape(len(param1), len(param2)) + grid['mean_test_score'].max()))\n",
    "            ax.set_xticklabels(['{:.2e}'.format(x) for x in param2] , Rotation=45, fontdict={\n",
    "            'horizontalalignment': 'right'})\n",
    "            ax.set_yticklabels(['{:.2e}'.format(x) for x in param1])\n",
    "            plt.title(name_model, fontsize =16)\n",
    "            plt.ylabel(name1, fontsize =14)\n",
    "            plt.xlabel(name2, fontsize =14)\n",
    "            plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66dd07c-6770-4bd2-a63c-98e64b1e1e53",
   "metadata": {},
   "source": [
    "## Non supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53570afc-29a7-4adb-899c-f1fe71a714fa",
   "metadata": {},
   "source": [
    "### ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2401be-fe9d-4493-b34d-1b7038aabef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scree_plot(pca):\n",
    "    '''\n",
    "    visualiser la progression de l'inertie par l'ajout de nouvelle composantes\n",
    "    '''\n",
    "    scree = pca.explained_variance_ratio_*100\n",
    "    plt.bar(np.arange(len(scree))+1, scree)\n",
    "    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')\n",
    "    plt.xlabel(\"rang de l'axe d'inertie\")\n",
    "    plt.ylabel(\"pourcentage d'inertie\")\n",
    "    plt.title(\"Eboulis des valeurs propres\")\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b87309-f6af-4f9f-b24b-895ce25cdbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def display_circles(n_comp, pca, axis_ranks, labels=None, label_rotation=0, lims=None):\n",
    "    '''\n",
    "    représente les axes sur le cercle des correlations\n",
    "    '''\n",
    "    for d1, d2 in axis_ranks: # On affiche les 3 premiers plans factoriels, donc les 6 premières composantes\n",
    "        if d2 < n_comp:\n",
    "\n",
    "            # initialisation de la figure\n",
    "            fig, ax = plt.subplots(figsize=(7,6))\n",
    "\n",
    "            # détermination des limites du graphique\n",
    "            if lims is not None :\n",
    "                xmin, xmax, ymin, ymax = lims\n",
    "            elif pca.components_.shape[1] < 30 :\n",
    "                xmin, xmax, ymin, ymax = -1, 1, -1, 1\n",
    "            else :\n",
    "                xmin, xmax, ymin, ymax = min(pca.components_[d1,:]), max(pca.components_[d1,:]), min(pca.components_[d2,:]), max(pca.components_[d2,:])\n",
    "\n",
    "            # affichage des flèches\n",
    "            # s'il y a plus de 30 flèches, on n'affiche pas le triangle à leur extrémité\n",
    "            if pca.components_.shape[1] < 30 :\n",
    "                plt.quiver(np.zeros(pca.components_.shape[1]), np.zeros(pca.components_.shape[1]),\n",
    "                   pca.components_[d1,:], pca.components_[d2,:], \n",
    "                   angles='xy', scale_units='xy', scale=1, color=\"grey\")\n",
    "                # (voir la doc : https://matplotlib.org/api/_as_gen/matplotlib.pyplot.quiver.html)\n",
    "            else:\n",
    "                lines = [[[0,0],[x,y]] for x,y in pca.components_[[d1,d2]].T]\n",
    "                ax.add_collection(LineCollection(lines, axes=ax, alpha=.1, color='black'))\n",
    "            \n",
    "            # affichage des noms des variables  \n",
    "            if labels is not None:  \n",
    "                for i,(x, y) in enumerate(pca.components_[[d1,d2]].T):\n",
    "                    if x >= xmin and x <= xmax and y >= ymin and y <= ymax :\n",
    "                        plt.text(x, y, labels[i], fontsize='14', ha='center', va='center', rotation=label_rotation, color=\"blue\", alpha=0.5)\n",
    "            \n",
    "            # affichage du cercle\n",
    "            circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
    "            plt.gca().add_artist(circle)\n",
    "\n",
    "            # définition des limites du graphique\n",
    "            plt.xlim(xmin, xmax)\n",
    "            plt.ylim(ymin, ymax)\n",
    "        \n",
    "            # affichage des lignes horizontales et verticales\n",
    "            plt.plot([-1, 1], [0, 0], color='grey', ls='--')\n",
    "            plt.plot([0, 0], [-1, 1], color='grey', ls='--')\n",
    "\n",
    "            # nom des axes, avec le pourcentage d'inertie expliqué\n",
    "            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n",
    "            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n",
    "\n",
    "            plt.title(\"Cercle des corrélations (F{} et F{})\".format(d1+1, d2+1))\n",
    "            plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3369fe-c721-4f3d-92e3-89ddf8f36355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def display_circles_3d(n_comp, pca, axis_ranks, labels=None, label_rotation=0, lims=None):\n",
    "    '''\n",
    "    représente les axes sur le cercle des correlations\n",
    "    '''\n",
    "    for d1, d2, d3 in axis_ranks: # On affiche les 3 premiers plans factoriels, donc les 6 premières composantes\n",
    "        if d3 < n_comp:\n",
    "\n",
    "            # initialisation de la figure\n",
    "            fig, ax = plt.subplots(figsize=(8,8))\n",
    "            ax = plt.axes(projection='3d')\n",
    "\n",
    "            # détermination des limites du graphique\n",
    "            if lims is not None :\n",
    "                xmin, xmax, ymin, ymax, zmin, zmax = lims\n",
    "            elif pca.components_.shape[1] < 30 :\n",
    "                xmin, xmax, ymin, ymax, zmin, zmax = -1, 1, -1, 1, -1, 1\n",
    "            else :\n",
    "                xmin, xmax, ymin, ymax, zmin, zmax = min(pca.components_[d1,:]), max(pca.components_[d1,:]), min(pca.components_[d2,:]), max(pca.components_[d2,:]), min(pca.components_[d3,:]), max(pca.components_[d3,:])\n",
    "\n",
    "            # affichage des flèches\n",
    "            lines = [[[0,0,0,x,y,z]] for x,y,z in pca.components_[[d1,d2,d3]].T]\n",
    "            X, Y, Z, U, V, W = np.array(lines).T.tolist()\n",
    "            ax.quiver(X, Y, Z, U, V, W)\n",
    "            \n",
    "            # affichage des noms des variables  \n",
    "            if labels is not None:  \n",
    "                for i,(x, y, z) in enumerate(pca.components_[[d1,d2,d3]].T):\n",
    "                    if x >= xmin and x <= xmax and y >= ymin and y <= ymax and z >= zmin and z <= zmax :\n",
    "                        ax.text(x, y, z, labels[i], fontsize='12', ha='center', va='center', rotation=label_rotation, color=\"blue\", alpha=0.5)\n",
    "            \n",
    "\n",
    "            # définition des limites du graphique\n",
    "            ax.set_xlim(xmin, xmax)\n",
    "            ax.set_ylim(ymin, ymax)\n",
    "            ax.set_zlim(zmin, zmax)\n",
    "        \n",
    "            # affichage des lignes horizontales et verticales\n",
    "            #plt.plot([-1, 1], [0, 0], color='grey', ls='--')\n",
    "            #plt.plot([0, 0], [-1, 1], color='grey', ls='--')\n",
    "\n",
    "            # nom des axes, avec le pourcentage d'inertie expliqué\n",
    "            ax.set_xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n",
    "            ax.set_ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n",
    "            ax.set_zlabel('F{} ({}%)'.format(d3+1, round(100*pca.explained_variance_ratio_[d3],1)))\n",
    "\n",
    "            plt.title(\"Cercle des corrélations (F{}, F{} et F{})\".format(d1+1, d2+1, d3+1))\n",
    "            plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a38d26-6161-488d-8346-f5ba5d6c8f05",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93459a-12fb-4d1d-a5fc-6cf8b4aba8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "def plot_dendrogram(Z, names):\n",
    "    plt.figure(figsize=(10,25))\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    plt.xlabel('distance')\n",
    "    dendrogram(\n",
    "        Z,\n",
    "        labels = names,\n",
    "        orientation = \"left\",\n",
    "    )\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
